{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf997a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        # print('begin _build_tree', X.shape, y.shape)\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes, count = np.unique(y, return_counts=True)\n",
    "        # print('unique_classes', unique_classes, 'counts:', counts)\n",
    "\n",
    "\n",
    "        # end ealry\n",
    "        if len(unique_classes) == 1 or  depth == self.max_depth:\n",
    "            # print('bingo stop')\n",
    "            return unique_classes[np.argmax(count)]\n",
    "        \n",
    "        # To split, split with each feature\n",
    "        # with each feature, split by each value, save the one with best gini\n",
    "        best_split = None\n",
    "        best_gini = 1.0\n",
    "\n",
    "        for feature_idx in range(n_features):\n",
    "            \n",
    "            feature = X[:, feature_idx]\n",
    "            unique_values = np.unique(feature)\n",
    "            # print('unique_values', len(unique_values), unique_values)\n",
    "\n",
    "            for value in unique_values:\n",
    "                left_mask = X[:, feature_idx] <= value # return mask True or False (can work as index)\n",
    "                right_mask = X[:, feature_idx] > value\n",
    "\n",
    "                if len(y[left_mask]) >= 1 and len(y[right_mask]) >= 1:\n",
    "                    left_gini = self._gini(y[left_mask])\n",
    "                    right_gini = self._gini(y[right_mask])\n",
    "                    split_gini = len(y[left_mask]) / n_samples * left_gini + len(y[right_mask]) / n_samples * right_gini\n",
    "                    \n",
    "                    if split_gini < best_gini:\n",
    "                        best_gini = split_gini\n",
    "                        best_split = (feature_idx, value)\n",
    "\n",
    "        # if the split didn't give a good result, just return class with the highest rate\n",
    "        if best_gini == 1.0:\n",
    "            return unique_classes[np.argmax(count)]\n",
    "        \n",
    "        feature_idx, value = best_split\n",
    "        left_mask = X[:, feature_idx] <= value\n",
    "        right_mask = X[:, feature_idx] > value\n",
    "\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth+1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth+1)\n",
    "\n",
    "        return (feature_idx, value, left_subtree, right_subtree)\n",
    "\n",
    "\n",
    "\n",
    "    def _gini(self, y):\n",
    "        _, count = np.unique(y, return_counts=True)\n",
    "        rate = count / len(y)\n",
    "        gini = 1.0 - np.sum(rate ** 2)\n",
    "        return gini\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            # print('self.root', self.root)\n",
    "            predict = self._predict(x, self.root)\n",
    "            predictions.append(predict)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x, node):\n",
    "        # The base code: if isinstance(node, int32)\n",
    "        # But the result can be int64 and int, we should do like below:\n",
    "        if not isinstance(node, tuple):\n",
    "            return node\n",
    "        # print('node', node)\n",
    "        feature_idx, value, left_subtree, right_subtree = node\n",
    "        if x[feature_idx] <= value:\n",
    "            return self._predict(x, left_subtree)\n",
    "        else:\n",
    "            return self._predict(x, right_subtree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba75e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a5cf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5221de02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acuracy: 0.95\n",
      "Test accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree(max_depth=2)\n",
    "tree.fit(X_train, y_train)\n",
    "train_accuracy = accuracy_score(y_train, tree.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, tree.predict(X_test))\n",
    "\n",
    "print(f\"Train acuracy: {train_accuracy}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
